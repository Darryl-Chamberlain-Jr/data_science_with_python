{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87a7010",
   "metadata": {},
   "source": [
    "# Useful Functions on DataFrames\n",
    "Here are some of the most useful functions on DataFrames. \n",
    "\n",
    "**df.apply()** - Apply a function along *an* axis of the DataFrame (either rows or columns). See the \"08_Dataframe Apply\" section for an example. <br>\n",
    "**df.columns()** - Returns a list of column names. Column names can be used as keys to extract columns from a dataframe. <br>\n",
    "**df.head(#)** and **df.tail(#)** - Returns the first (head) or last (tail) # rows of a dataframe. <br>\n",
    "**df.describe()** - Returns quick statistics by column, including mean, median, <br>\n",
    "**df.sort_values()** - Sort values in a column, similar to using a Filter in Excel. Note that the index remains the same. <br>\n",
    "**df.sort_index()** - Sort by index. Useful for returning order after sorting by a certain column. <br>\n",
    "**df.groupby()** - Collapse rows together that share one or more same column values. Useful for going from a fine to coarse analysis. For example, if data is saved by country, we could groupby country and analyze by region or continent. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391afc9",
   "metadata": {},
   "source": [
    "## Initial dataframe to explore functions in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4df6c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For this example, I downloaded May 2022 data\n",
    "# This will take 1-2 minutes as there are 400,000+ rows of data!\n",
    "df = pd.read_excel(\"../Datasets/all_data_M_2022.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c2399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e68b42a",
   "metadata": {},
   "source": [
    "## df.describe()\n",
    "\n",
    "Note that Python will run statistics on ALL columns even if the values don't make sense. We would also expect a column like 'H_MEDIAN' to have statistics, but columns with non-numeric values will not provide a describe column. These columns need to be modified first like we did in the \n",
    "Sanitizing Data Example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Quick statistics by column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d679725",
   "metadata": {},
   "source": [
    "### Sanitizing Columns for expanded df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7f051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_modify = ['H_MEAN', 'A_MEAN', 'MEAN_PRSE', 'H_PCT10', \n",
    "                     'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', \n",
    "                     'A_PCT10', 'A_PCT25', 'A_MEDIAN', 'A_PCT75', \n",
    "                     'A_PCT90'\n",
    "                    ]\n",
    "\n",
    "# Splits columns by number type wanted\n",
    "int_columns = ['A_MEAN', 'A_PCT10', 'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90']\n",
    "float_columns = ['H_MEAN', 'MEAN_PRSE', 'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90']\n",
    "\n",
    "# Initialize dict of column and its type\n",
    "dict_column_and_type = {}\n",
    "\n",
    "# Attach column name with the data type\n",
    "for column_name in columns_to_modify:\n",
    "    if column_name in int_columns:\n",
    "        # 'Int64' is needed when mixing ints with pandas.NA\n",
    "        dict_column_and_type[column_name] = 'Int64'\n",
    "    else:\n",
    "        # 'Float64' is needed when mixing floats with pandas.NA\n",
    "        dict_column_and_type[column_name] = 'Float64'\n",
    "\n",
    "# To use .apply, we want the input of the definition to be the value in the table\n",
    "def remove_commas(text):\n",
    "    return text.replace(\",\", \"\")\n",
    "\n",
    "def replace_symbols(text):\n",
    "    # pd.NA is Not a Number\n",
    "    new_text = text.replace(\"*\", pd.NA)\n",
    "    new_text = new_text.replace(\"#\", pd.NA) # Notice we are modifying our new_text variable\n",
    "    new_text = new_text.replace(np.nan, pd.NA) # Notice we are AGAIN modifying our new_text variable\n",
    "    # While RegEx could have done this all in a single step, it was easy to make a few .replace() statements to achieve the same purpose\n",
    "    return new_text\n",
    "\n",
    "# Initialize our sanitized dataframe\n",
    "sanitized_df = df.copy()\n",
    "\n",
    "# Apply our two functions\n",
    "sanitized_df[columns_to_modify] = sanitized_df[columns_to_modify].apply(remove_commas)\n",
    "sanitized_df[columns_to_modify] = sanitized_df[columns_to_modify].apply(replace_symbols)\n",
    "\n",
    "# Using the dictonary, we cast each column as its associated data type\n",
    "sanitized_df = sanitized_df.astype(dict_column_and_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ad8a2",
   "metadata": {},
   "source": [
    "## Revised df for df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d8331",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_df.describe() # Once we clean those columns, they appear in the .describe() output!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd90085",
   "metadata": {},
   "source": [
    "## Counting and Sorting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_titles = sanitized_df['AREA_TITLE'].value_counts() # List of all unique entiries and their count in a column\n",
    "area_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7564c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_df.sort_values(by='H_MEDIAN', inplace=True) # Sort by a column. Note the index remains\n",
    "sanitized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab963fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_df.sort_index() # Sort by index. Useful for returning order after sorting by a certain column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab53a0bb",
   "metadata": {},
   "source": [
    "## df.groupby().how_to_group()\n",
    "groupby is used when we want to combine rows based on one or more columns. We need to specify how we are combining the other columns though! In the example below, we specify the column we want to group everything by (AREA_TITLE) and the columns we want to combine based on AREA_TITLE. We then specify we want to combine matching AREA_TITLE rows by averaging the values (e.g., taking the mean). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07183352",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_focus_on=['AREA_TITLE', 'H_MEAN', 'A_MEAN', 'H_MEDIAN', 'A_MEDIAN']\n",
    "grouped_df=sanitized_df[columns_to_focus_on].groupby(['AREA_TITLE']).mean()\n",
    "grouped_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
